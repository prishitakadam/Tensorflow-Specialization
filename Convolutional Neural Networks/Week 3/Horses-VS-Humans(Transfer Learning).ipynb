{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbFmQdsZs5eW"
   },
   "outputs": [],
   "source": [
    "# ATTENTION: Please do not alter any of the provided code in the exercise. Only add your own code where indicated\n",
    "# ATTENTION: Please do not add or remove any cells in the exercise. The grader will check specific cells based on the cell position.\n",
    "# ATTENTION: Please use the provided epoch values when training.\n",
    "\n",
    "# Import all the necessary files!\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1xJZ5glPPCRz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_564 (Conv2D)             (None, 74, 74, 32)   864         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_564 (BatchN (None, 74, 74, 32)   96          conv2d_564[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_564 (Activation)     (None, 74, 74, 32)   0           batch_normalization_564[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_565 (Conv2D)             (None, 72, 72, 32)   9216        activation_564[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_565 (BatchN (None, 72, 72, 32)   96          conv2d_565[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_565 (Activation)     (None, 72, 72, 32)   0           batch_normalization_565[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_566 (Conv2D)             (None, 72, 72, 64)   18432       activation_565[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_566 (BatchN (None, 72, 72, 64)   192         conv2d_566[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_566 (Activation)     (None, 72, 72, 64)   0           batch_normalization_566[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling2D) (None, 35, 35, 64)   0           activation_566[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_567 (Conv2D)             (None, 35, 35, 80)   5120        max_pooling2d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_567 (BatchN (None, 35, 35, 80)   240         conv2d_567[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_567 (Activation)     (None, 35, 35, 80)   0           batch_normalization_567[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_568 (Conv2D)             (None, 33, 33, 192)  138240      activation_567[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_568 (BatchN (None, 33, 33, 192)  576         conv2d_568[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_568 (Activation)     (None, 33, 33, 192)  0           batch_normalization_568[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling2D) (None, 16, 16, 192)  0           activation_568[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_572 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_572 (BatchN (None, 16, 16, 64)   192         conv2d_572[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_572 (Activation)     (None, 16, 16, 64)   0           batch_normalization_572[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_570 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_573 (Conv2D)             (None, 16, 16, 96)   55296       activation_572[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_570 (BatchN (None, 16, 16, 48)   144         conv2d_570[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_573 (BatchN (None, 16, 16, 96)   288         conv2d_573[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_570 (Activation)     (None, 16, 16, 48)   0           batch_normalization_570[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_573 (Activation)     (None, 16, 16, 96)   0           batch_normalization_573[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_54 (AveragePo (None, 16, 16, 192)  0           max_pooling2d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_569 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_571 (Conv2D)             (None, 16, 16, 64)   76800       activation_570[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_574 (Conv2D)             (None, 16, 16, 96)   82944       activation_573[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_575 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_54[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_569 (BatchN (None, 16, 16, 64)   192         conv2d_569[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_571 (BatchN (None, 16, 16, 64)   192         conv2d_571[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_574 (BatchN (None, 16, 16, 96)   288         conv2d_574[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_575 (BatchN (None, 16, 16, 32)   96          conv2d_575[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_569 (Activation)     (None, 16, 16, 64)   0           batch_normalization_569[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_571 (Activation)     (None, 16, 16, 64)   0           batch_normalization_571[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_574 (Activation)     (None, 16, 16, 96)   0           batch_normalization_574[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_575 (Activation)     (None, 16, 16, 32)   0           batch_normalization_575[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_569[0][0]             \n",
      "                                                                 activation_571[0][0]             \n",
      "                                                                 activation_574[0][0]             \n",
      "                                                                 activation_575[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_579 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_579 (BatchN (None, 16, 16, 64)   192         conv2d_579[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_579 (Activation)     (None, 16, 16, 64)   0           batch_normalization_579[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_577 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_580 (Conv2D)             (None, 16, 16, 96)   55296       activation_579[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_577 (BatchN (None, 16, 16, 48)   144         conv2d_577[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_580 (BatchN (None, 16, 16, 96)   288         conv2d_580[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_577 (Activation)     (None, 16, 16, 48)   0           batch_normalization_577[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_580 (Activation)     (None, 16, 16, 96)   0           batch_normalization_580[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_55 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_576 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_578 (Conv2D)             (None, 16, 16, 64)   76800       activation_577[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_581 (Conv2D)             (None, 16, 16, 96)   82944       activation_580[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_582 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_55[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_576 (BatchN (None, 16, 16, 64)   192         conv2d_576[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_578 (BatchN (None, 16, 16, 64)   192         conv2d_578[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_581 (BatchN (None, 16, 16, 96)   288         conv2d_581[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_582 (BatchN (None, 16, 16, 64)   192         conv2d_582[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_576 (Activation)     (None, 16, 16, 64)   0           batch_normalization_576[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_578 (Activation)     (None, 16, 16, 64)   0           batch_normalization_578[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_581 (Activation)     (None, 16, 16, 96)   0           batch_normalization_581[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_582 (Activation)     (None, 16, 16, 64)   0           batch_normalization_582[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_576[0][0]             \n",
      "                                                                 activation_578[0][0]             \n",
      "                                                                 activation_581[0][0]             \n",
      "                                                                 activation_582[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_586 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_586 (BatchN (None, 16, 16, 64)   192         conv2d_586[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_586 (Activation)     (None, 16, 16, 64)   0           batch_normalization_586[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_584 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_587 (Conv2D)             (None, 16, 16, 96)   55296       activation_586[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_584 (BatchN (None, 16, 16, 48)   144         conv2d_584[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_587 (BatchN (None, 16, 16, 96)   288         conv2d_587[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_584 (Activation)     (None, 16, 16, 48)   0           batch_normalization_584[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_587 (Activation)     (None, 16, 16, 96)   0           batch_normalization_587[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_56 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_583 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_585 (Conv2D)             (None, 16, 16, 64)   76800       activation_584[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_588 (Conv2D)             (None, 16, 16, 96)   82944       activation_587[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_589 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_56[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_583 (BatchN (None, 16, 16, 64)   192         conv2d_583[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_585 (BatchN (None, 16, 16, 64)   192         conv2d_585[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_588 (BatchN (None, 16, 16, 96)   288         conv2d_588[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_589 (BatchN (None, 16, 16, 64)   192         conv2d_589[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_583 (Activation)     (None, 16, 16, 64)   0           batch_normalization_583[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_585 (Activation)     (None, 16, 16, 64)   0           batch_normalization_585[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_588 (Activation)     (None, 16, 16, 96)   0           batch_normalization_588[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_589 (Activation)     (None, 16, 16, 64)   0           batch_normalization_589[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_583[0][0]             \n",
      "                                                                 activation_585[0][0]             \n",
      "                                                                 activation_588[0][0]             \n",
      "                                                                 activation_589[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_591 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_591 (BatchN (None, 16, 16, 64)   192         conv2d_591[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_591 (Activation)     (None, 16, 16, 64)   0           batch_normalization_591[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_592 (Conv2D)             (None, 16, 16, 96)   55296       activation_591[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_592 (BatchN (None, 16, 16, 96)   288         conv2d_592[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_592 (Activation)     (None, 16, 16, 96)   0           batch_normalization_592[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_590 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_593 (Conv2D)             (None, 7, 7, 96)     82944       activation_592[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_590 (BatchN (None, 7, 7, 384)    1152        conv2d_590[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_593 (BatchN (None, 7, 7, 96)     288         conv2d_593[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_590 (Activation)     (None, 7, 7, 384)    0           batch_normalization_590[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_593 (Activation)     (None, 7, 7, 96)     0           batch_normalization_593[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling2D) (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_590[0][0]             \n",
      "                                                                 activation_593[0][0]             \n",
      "                                                                 max_pooling2d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_598 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_598 (BatchN (None, 7, 7, 128)    384         conv2d_598[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_598 (Activation)     (None, 7, 7, 128)    0           batch_normalization_598[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_599 (Conv2D)             (None, 7, 7, 128)    114688      activation_598[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_599 (BatchN (None, 7, 7, 128)    384         conv2d_599[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_599 (Activation)     (None, 7, 7, 128)    0           batch_normalization_599[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_595 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_600 (Conv2D)             (None, 7, 7, 128)    114688      activation_599[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_595 (BatchN (None, 7, 7, 128)    384         conv2d_595[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_600 (BatchN (None, 7, 7, 128)    384         conv2d_600[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_595 (Activation)     (None, 7, 7, 128)    0           batch_normalization_595[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_600 (Activation)     (None, 7, 7, 128)    0           batch_normalization_600[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_596 (Conv2D)             (None, 7, 7, 128)    114688      activation_595[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_601 (Conv2D)             (None, 7, 7, 128)    114688      activation_600[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_596 (BatchN (None, 7, 7, 128)    384         conv2d_596[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_601 (BatchN (None, 7, 7, 128)    384         conv2d_601[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_596 (Activation)     (None, 7, 7, 128)    0           batch_normalization_596[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_601 (Activation)     (None, 7, 7, 128)    0           batch_normalization_601[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_57 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_594 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_597 (Conv2D)             (None, 7, 7, 192)    172032      activation_596[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_602 (Conv2D)             (None, 7, 7, 192)    172032      activation_601[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_603 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_57[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_594 (BatchN (None, 7, 7, 192)    576         conv2d_594[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_597 (BatchN (None, 7, 7, 192)    576         conv2d_597[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_602 (BatchN (None, 7, 7, 192)    576         conv2d_602[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_603 (BatchN (None, 7, 7, 192)    576         conv2d_603[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_594 (Activation)     (None, 7, 7, 192)    0           batch_normalization_594[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_597 (Activation)     (None, 7, 7, 192)    0           batch_normalization_597[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_602 (Activation)     (None, 7, 7, 192)    0           batch_normalization_602[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_603 (Activation)     (None, 7, 7, 192)    0           batch_normalization_603[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_594[0][0]             \n",
      "                                                                 activation_597[0][0]             \n",
      "                                                                 activation_602[0][0]             \n",
      "                                                                 activation_603[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_608 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_608 (BatchN (None, 7, 7, 160)    480         conv2d_608[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_608 (Activation)     (None, 7, 7, 160)    0           batch_normalization_608[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_609 (Conv2D)             (None, 7, 7, 160)    179200      activation_608[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_609 (BatchN (None, 7, 7, 160)    480         conv2d_609[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_609 (Activation)     (None, 7, 7, 160)    0           batch_normalization_609[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_605 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_610 (Conv2D)             (None, 7, 7, 160)    179200      activation_609[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_605 (BatchN (None, 7, 7, 160)    480         conv2d_605[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_610 (BatchN (None, 7, 7, 160)    480         conv2d_610[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_605 (Activation)     (None, 7, 7, 160)    0           batch_normalization_605[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_610 (Activation)     (None, 7, 7, 160)    0           batch_normalization_610[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_606 (Conv2D)             (None, 7, 7, 160)    179200      activation_605[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_611 (Conv2D)             (None, 7, 7, 160)    179200      activation_610[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_606 (BatchN (None, 7, 7, 160)    480         conv2d_606[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_611 (BatchN (None, 7, 7, 160)    480         conv2d_611[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_606 (Activation)     (None, 7, 7, 160)    0           batch_normalization_606[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_611 (Activation)     (None, 7, 7, 160)    0           batch_normalization_611[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_58 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_604 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_607 (Conv2D)             (None, 7, 7, 192)    215040      activation_606[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_612 (Conv2D)             (None, 7, 7, 192)    215040      activation_611[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_613 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_58[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_604 (BatchN (None, 7, 7, 192)    576         conv2d_604[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_607 (BatchN (None, 7, 7, 192)    576         conv2d_607[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_612 (BatchN (None, 7, 7, 192)    576         conv2d_612[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_613 (BatchN (None, 7, 7, 192)    576         conv2d_613[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_604 (Activation)     (None, 7, 7, 192)    0           batch_normalization_604[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_607 (Activation)     (None, 7, 7, 192)    0           batch_normalization_607[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_612 (Activation)     (None, 7, 7, 192)    0           batch_normalization_612[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_613 (Activation)     (None, 7, 7, 192)    0           batch_normalization_613[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_604[0][0]             \n",
      "                                                                 activation_607[0][0]             \n",
      "                                                                 activation_612[0][0]             \n",
      "                                                                 activation_613[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_618 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_618 (BatchN (None, 7, 7, 160)    480         conv2d_618[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_618 (Activation)     (None, 7, 7, 160)    0           batch_normalization_618[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_619 (Conv2D)             (None, 7, 7, 160)    179200      activation_618[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_619 (BatchN (None, 7, 7, 160)    480         conv2d_619[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_619 (Activation)     (None, 7, 7, 160)    0           batch_normalization_619[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_615 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_620 (Conv2D)             (None, 7, 7, 160)    179200      activation_619[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_615 (BatchN (None, 7, 7, 160)    480         conv2d_615[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_620 (BatchN (None, 7, 7, 160)    480         conv2d_620[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_615 (Activation)     (None, 7, 7, 160)    0           batch_normalization_615[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_620 (Activation)     (None, 7, 7, 160)    0           batch_normalization_620[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_616 (Conv2D)             (None, 7, 7, 160)    179200      activation_615[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_621 (Conv2D)             (None, 7, 7, 160)    179200      activation_620[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_616 (BatchN (None, 7, 7, 160)    480         conv2d_616[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_621 (BatchN (None, 7, 7, 160)    480         conv2d_621[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_616 (Activation)     (None, 7, 7, 160)    0           batch_normalization_616[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_621 (Activation)     (None, 7, 7, 160)    0           batch_normalization_621[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_59 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_614 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_617 (Conv2D)             (None, 7, 7, 192)    215040      activation_616[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_622 (Conv2D)             (None, 7, 7, 192)    215040      activation_621[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_623 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_59[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_614 (BatchN (None, 7, 7, 192)    576         conv2d_614[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_617 (BatchN (None, 7, 7, 192)    576         conv2d_617[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_622 (BatchN (None, 7, 7, 192)    576         conv2d_622[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_623 (BatchN (None, 7, 7, 192)    576         conv2d_623[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_614 (Activation)     (None, 7, 7, 192)    0           batch_normalization_614[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_617 (Activation)     (None, 7, 7, 192)    0           batch_normalization_617[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_622 (Activation)     (None, 7, 7, 192)    0           batch_normalization_622[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_623 (Activation)     (None, 7, 7, 192)    0           batch_normalization_623[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_614[0][0]             \n",
      "                                                                 activation_617[0][0]             \n",
      "                                                                 activation_622[0][0]             \n",
      "                                                                 activation_623[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_628 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_628 (BatchN (None, 7, 7, 192)    576         conv2d_628[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_628 (Activation)     (None, 7, 7, 192)    0           batch_normalization_628[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_629 (Conv2D)             (None, 7, 7, 192)    258048      activation_628[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_629 (BatchN (None, 7, 7, 192)    576         conv2d_629[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_629 (Activation)     (None, 7, 7, 192)    0           batch_normalization_629[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_625 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_630 (Conv2D)             (None, 7, 7, 192)    258048      activation_629[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_625 (BatchN (None, 7, 7, 192)    576         conv2d_625[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_630 (BatchN (None, 7, 7, 192)    576         conv2d_630[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_625 (Activation)     (None, 7, 7, 192)    0           batch_normalization_625[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_630 (Activation)     (None, 7, 7, 192)    0           batch_normalization_630[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_626 (Conv2D)             (None, 7, 7, 192)    258048      activation_625[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_631 (Conv2D)             (None, 7, 7, 192)    258048      activation_630[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_626 (BatchN (None, 7, 7, 192)    576         conv2d_626[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_631 (BatchN (None, 7, 7, 192)    576         conv2d_631[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_626 (Activation)     (None, 7, 7, 192)    0           batch_normalization_626[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_631 (Activation)     (None, 7, 7, 192)    0           batch_normalization_631[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_60 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_624 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_627 (Conv2D)             (None, 7, 7, 192)    258048      activation_626[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_632 (Conv2D)             (None, 7, 7, 192)    258048      activation_631[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_633 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_60[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_624 (BatchN (None, 7, 7, 192)    576         conv2d_624[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_627 (BatchN (None, 7, 7, 192)    576         conv2d_627[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_632 (BatchN (None, 7, 7, 192)    576         conv2d_632[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_633 (BatchN (None, 7, 7, 192)    576         conv2d_633[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_624 (Activation)     (None, 7, 7, 192)    0           batch_normalization_624[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_627 (Activation)     (None, 7, 7, 192)    0           batch_normalization_627[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_632 (Activation)     (None, 7, 7, 192)    0           batch_normalization_632[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_633 (Activation)     (None, 7, 7, 192)    0           batch_normalization_633[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_624[0][0]             \n",
      "                                                                 activation_627[0][0]             \n",
      "                                                                 activation_632[0][0]             \n",
      "                                                                 activation_633[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_636 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_636 (BatchN (None, 7, 7, 192)    576         conv2d_636[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_636 (Activation)     (None, 7, 7, 192)    0           batch_normalization_636[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_637 (Conv2D)             (None, 7, 7, 192)    258048      activation_636[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_637 (BatchN (None, 7, 7, 192)    576         conv2d_637[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_637 (Activation)     (None, 7, 7, 192)    0           batch_normalization_637[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_634 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_638 (Conv2D)             (None, 7, 7, 192)    258048      activation_637[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_634 (BatchN (None, 7, 7, 192)    576         conv2d_634[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_638 (BatchN (None, 7, 7, 192)    576         conv2d_638[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_634 (Activation)     (None, 7, 7, 192)    0           batch_normalization_634[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_638 (Activation)     (None, 7, 7, 192)    0           batch_normalization_638[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_635 (Conv2D)             (None, 3, 3, 320)    552960      activation_634[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_639 (Conv2D)             (None, 3, 3, 192)    331776      activation_638[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_635 (BatchN (None, 3, 3, 320)    960         conv2d_635[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_639 (BatchN (None, 3, 3, 192)    576         conv2d_639[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_635 (Activation)     (None, 3, 3, 320)    0           batch_normalization_635[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_639 (Activation)     (None, 3, 3, 192)    0           batch_normalization_639[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling2D) (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_635[0][0]             \n",
      "                                                                 activation_639[0][0]             \n",
      "                                                                 max_pooling2d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_644 (Conv2D)             (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_644 (BatchN (None, 3, 3, 448)    1344        conv2d_644[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_644 (Activation)     (None, 3, 3, 448)    0           batch_normalization_644[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_641 (Conv2D)             (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_645 (Conv2D)             (None, 3, 3, 384)    1548288     activation_644[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_641 (BatchN (None, 3, 3, 384)    1152        conv2d_641[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_645 (BatchN (None, 3, 3, 384)    1152        conv2d_645[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_641 (Activation)     (None, 3, 3, 384)    0           batch_normalization_641[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_645 (Activation)     (None, 3, 3, 384)    0           batch_normalization_645[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_642 (Conv2D)             (None, 3, 3, 384)    442368      activation_641[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_643 (Conv2D)             (None, 3, 3, 384)    442368      activation_641[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_646 (Conv2D)             (None, 3, 3, 384)    442368      activation_645[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_647 (Conv2D)             (None, 3, 3, 384)    442368      activation_645[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_61 (AveragePo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_640 (Conv2D)             (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_642 (BatchN (None, 3, 3, 384)    1152        conv2d_642[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_643 (BatchN (None, 3, 3, 384)    1152        conv2d_643[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_646 (BatchN (None, 3, 3, 384)    1152        conv2d_646[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_647 (BatchN (None, 3, 3, 384)    1152        conv2d_647[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_648 (Conv2D)             (None, 3, 3, 192)    245760      average_pooling2d_61[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_640 (BatchN (None, 3, 3, 320)    960         conv2d_640[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_642 (Activation)     (None, 3, 3, 384)    0           batch_normalization_642[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_643 (Activation)     (None, 3, 3, 384)    0           batch_normalization_643[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_646 (Activation)     (None, 3, 3, 384)    0           batch_normalization_646[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_647 (Activation)     (None, 3, 3, 384)    0           batch_normalization_647[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_648 (BatchN (None, 3, 3, 192)    576         conv2d_648[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_640 (Activation)     (None, 3, 3, 320)    0           batch_normalization_640[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_642[0][0]             \n",
      "                                                                 activation_643[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 3, 3, 768)    0           activation_646[0][0]             \n",
      "                                                                 activation_647[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_648 (Activation)     (None, 3, 3, 192)    0           batch_normalization_648[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_640[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_12[0][0]             \n",
      "                                                                 activation_648[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_653 (Conv2D)             (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_653 (BatchN (None, 3, 3, 448)    1344        conv2d_653[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_653 (Activation)     (None, 3, 3, 448)    0           batch_normalization_653[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_650 (Conv2D)             (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_654 (Conv2D)             (None, 3, 3, 384)    1548288     activation_653[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_650 (BatchN (None, 3, 3, 384)    1152        conv2d_650[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_654 (BatchN (None, 3, 3, 384)    1152        conv2d_654[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_650 (Activation)     (None, 3, 3, 384)    0           batch_normalization_650[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_654 (Activation)     (None, 3, 3, 384)    0           batch_normalization_654[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_651 (Conv2D)             (None, 3, 3, 384)    442368      activation_650[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_652 (Conv2D)             (None, 3, 3, 384)    442368      activation_650[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_655 (Conv2D)             (None, 3, 3, 384)    442368      activation_654[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_656 (Conv2D)             (None, 3, 3, 384)    442368      activation_654[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_62 (AveragePo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_649 (Conv2D)             (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_651 (BatchN (None, 3, 3, 384)    1152        conv2d_651[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_652 (BatchN (None, 3, 3, 384)    1152        conv2d_652[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_655 (BatchN (None, 3, 3, 384)    1152        conv2d_655[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_656 (BatchN (None, 3, 3, 384)    1152        conv2d_656[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_657 (Conv2D)             (None, 3, 3, 192)    393216      average_pooling2d_62[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_649 (BatchN (None, 3, 3, 320)    960         conv2d_649[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_651 (Activation)     (None, 3, 3, 384)    0           batch_normalization_651[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_652 (Activation)     (None, 3, 3, 384)    0           batch_normalization_652[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_655 (Activation)     (None, 3, 3, 384)    0           batch_normalization_655[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_656 (Activation)     (None, 3, 3, 384)    0           batch_normalization_656[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_657 (BatchN (None, 3, 3, 192)    576         conv2d_657[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_649 (Activation)     (None, 3, 3, 320)    0           batch_normalization_649[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_651[0][0]             \n",
      "                                                                 activation_652[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 3, 3, 768)    0           activation_655[0][0]             \n",
      "                                                                 activation_656[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_657 (Activation)     (None, 3, 3, 192)    0           batch_normalization_657[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_649[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_13[0][0]             \n",
      "                                                                 activation_657[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "path_inception = f\"{getcwd()}/../tmp2/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "\n",
    "# Import the inception model  \n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "# Create an instance of the inception model from the local pre-trained weights\n",
    "local_weights_file = path_inception\n",
    "\n",
    "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
    "                                include_top = False, \n",
    "                                weights = None)# Your Code Here\n",
    "\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "# Make all the layers in the pre-trained model non-trainable\n",
    "for layer in pre_trained_model.layers:\n",
    "  # Your Code Here\n",
    "    layer.trainable = False\n",
    "  \n",
    "  \n",
    "# Print the model summary\n",
    "pre_trained_model.summary()\n",
    "\n",
    "# Expected Output is extremely large, but should end with:\n",
    "\n",
    "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
    "#                                                                 activation_276[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
    "#                                                                 activation_280[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
    "#                                                                 mixed9_1[0][0]                   \n",
    "#                                                                 concatenate_5[0][0]              \n",
    "#                                                                 activation_281[0][0]             \n",
    "#==================================================================================================\n",
    "#Total params: 21,802,784\n",
    "#Trainable params: 0\n",
    "#Non-trainable params: 21,802,784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CFsUlwdfs_wg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape:  (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "last_layer = pre_trained_model.get_layer('mixed7'\n",
    "                                         # Your Code Here\n",
    "                                        )\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output# Your Code Here\n",
    "\n",
    "# Expected Output:\n",
    "# ('last layer output shape: ', (None, 7, 7, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bsWZWp5oMq9"
   },
   "outputs": [],
   "source": [
    "# Define a Callback class that stops training once accuracy reaches 97.0%\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('acc')>0.97):\n",
    "            print(\"\\nReached 97.0% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMXb913pbvFg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_564 (Conv2D)             (None, 74, 74, 32)   864         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_564 (BatchN (None, 74, 74, 32)   96          conv2d_564[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_564 (Activation)     (None, 74, 74, 32)   0           batch_normalization_564[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_565 (Conv2D)             (None, 72, 72, 32)   9216        activation_564[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_565 (BatchN (None, 72, 72, 32)   96          conv2d_565[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_565 (Activation)     (None, 72, 72, 32)   0           batch_normalization_565[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_566 (Conv2D)             (None, 72, 72, 64)   18432       activation_565[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_566 (BatchN (None, 72, 72, 64)   192         conv2d_566[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_566 (Activation)     (None, 72, 72, 64)   0           batch_normalization_566[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling2D) (None, 35, 35, 64)   0           activation_566[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_567 (Conv2D)             (None, 35, 35, 80)   5120        max_pooling2d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_567 (BatchN (None, 35, 35, 80)   240         conv2d_567[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_567 (Activation)     (None, 35, 35, 80)   0           batch_normalization_567[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_568 (Conv2D)             (None, 33, 33, 192)  138240      activation_567[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_568 (BatchN (None, 33, 33, 192)  576         conv2d_568[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_568 (Activation)     (None, 33, 33, 192)  0           batch_normalization_568[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling2D) (None, 16, 16, 192)  0           activation_568[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_572 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_572 (BatchN (None, 16, 16, 64)   192         conv2d_572[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_572 (Activation)     (None, 16, 16, 64)   0           batch_normalization_572[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_570 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_573 (Conv2D)             (None, 16, 16, 96)   55296       activation_572[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_570 (BatchN (None, 16, 16, 48)   144         conv2d_570[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_573 (BatchN (None, 16, 16, 96)   288         conv2d_573[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_570 (Activation)     (None, 16, 16, 48)   0           batch_normalization_570[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_573 (Activation)     (None, 16, 16, 96)   0           batch_normalization_573[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_54 (AveragePo (None, 16, 16, 192)  0           max_pooling2d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_569 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_571 (Conv2D)             (None, 16, 16, 64)   76800       activation_570[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_574 (Conv2D)             (None, 16, 16, 96)   82944       activation_573[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_575 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_54[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_569 (BatchN (None, 16, 16, 64)   192         conv2d_569[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_571 (BatchN (None, 16, 16, 64)   192         conv2d_571[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_574 (BatchN (None, 16, 16, 96)   288         conv2d_574[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_575 (BatchN (None, 16, 16, 32)   96          conv2d_575[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_569 (Activation)     (None, 16, 16, 64)   0           batch_normalization_569[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_571 (Activation)     (None, 16, 16, 64)   0           batch_normalization_571[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_574 (Activation)     (None, 16, 16, 96)   0           batch_normalization_574[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_575 (Activation)     (None, 16, 16, 32)   0           batch_normalization_575[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_569[0][0]             \n",
      "                                                                 activation_571[0][0]             \n",
      "                                                                 activation_574[0][0]             \n",
      "                                                                 activation_575[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_579 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_579 (BatchN (None, 16, 16, 64)   192         conv2d_579[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_579 (Activation)     (None, 16, 16, 64)   0           batch_normalization_579[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_577 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_580 (Conv2D)             (None, 16, 16, 96)   55296       activation_579[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_577 (BatchN (None, 16, 16, 48)   144         conv2d_577[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_580 (BatchN (None, 16, 16, 96)   288         conv2d_580[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_577 (Activation)     (None, 16, 16, 48)   0           batch_normalization_577[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_580 (Activation)     (None, 16, 16, 96)   0           batch_normalization_580[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_55 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_576 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_578 (Conv2D)             (None, 16, 16, 64)   76800       activation_577[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_581 (Conv2D)             (None, 16, 16, 96)   82944       activation_580[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_582 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_55[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_576 (BatchN (None, 16, 16, 64)   192         conv2d_576[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_578 (BatchN (None, 16, 16, 64)   192         conv2d_578[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_581 (BatchN (None, 16, 16, 96)   288         conv2d_581[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_582 (BatchN (None, 16, 16, 64)   192         conv2d_582[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_576 (Activation)     (None, 16, 16, 64)   0           batch_normalization_576[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_578 (Activation)     (None, 16, 16, 64)   0           batch_normalization_578[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_581 (Activation)     (None, 16, 16, 96)   0           batch_normalization_581[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_582 (Activation)     (None, 16, 16, 64)   0           batch_normalization_582[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_576[0][0]             \n",
      "                                                                 activation_578[0][0]             \n",
      "                                                                 activation_581[0][0]             \n",
      "                                                                 activation_582[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_586 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_586 (BatchN (None, 16, 16, 64)   192         conv2d_586[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_586 (Activation)     (None, 16, 16, 64)   0           batch_normalization_586[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_584 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_587 (Conv2D)             (None, 16, 16, 96)   55296       activation_586[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_584 (BatchN (None, 16, 16, 48)   144         conv2d_584[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_587 (BatchN (None, 16, 16, 96)   288         conv2d_587[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_584 (Activation)     (None, 16, 16, 48)   0           batch_normalization_584[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_587 (Activation)     (None, 16, 16, 96)   0           batch_normalization_587[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_56 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_583 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_585 (Conv2D)             (None, 16, 16, 64)   76800       activation_584[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_588 (Conv2D)             (None, 16, 16, 96)   82944       activation_587[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_589 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_56[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_583 (BatchN (None, 16, 16, 64)   192         conv2d_583[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_585 (BatchN (None, 16, 16, 64)   192         conv2d_585[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_588 (BatchN (None, 16, 16, 96)   288         conv2d_588[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_589 (BatchN (None, 16, 16, 64)   192         conv2d_589[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_583 (Activation)     (None, 16, 16, 64)   0           batch_normalization_583[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_585 (Activation)     (None, 16, 16, 64)   0           batch_normalization_585[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_588 (Activation)     (None, 16, 16, 96)   0           batch_normalization_588[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_589 (Activation)     (None, 16, 16, 64)   0           batch_normalization_589[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_583[0][0]             \n",
      "                                                                 activation_585[0][0]             \n",
      "                                                                 activation_588[0][0]             \n",
      "                                                                 activation_589[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_591 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_591 (BatchN (None, 16, 16, 64)   192         conv2d_591[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_591 (Activation)     (None, 16, 16, 64)   0           batch_normalization_591[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_592 (Conv2D)             (None, 16, 16, 96)   55296       activation_591[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_592 (BatchN (None, 16, 16, 96)   288         conv2d_592[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_592 (Activation)     (None, 16, 16, 96)   0           batch_normalization_592[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_590 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_593 (Conv2D)             (None, 7, 7, 96)     82944       activation_592[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_590 (BatchN (None, 7, 7, 384)    1152        conv2d_590[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_593 (BatchN (None, 7, 7, 96)     288         conv2d_593[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_590 (Activation)     (None, 7, 7, 384)    0           batch_normalization_590[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_593 (Activation)     (None, 7, 7, 96)     0           batch_normalization_593[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling2D) (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_590[0][0]             \n",
      "                                                                 activation_593[0][0]             \n",
      "                                                                 max_pooling2d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_598 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_598 (BatchN (None, 7, 7, 128)    384         conv2d_598[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_598 (Activation)     (None, 7, 7, 128)    0           batch_normalization_598[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_599 (Conv2D)             (None, 7, 7, 128)    114688      activation_598[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_599 (BatchN (None, 7, 7, 128)    384         conv2d_599[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_599 (Activation)     (None, 7, 7, 128)    0           batch_normalization_599[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_595 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_600 (Conv2D)             (None, 7, 7, 128)    114688      activation_599[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_595 (BatchN (None, 7, 7, 128)    384         conv2d_595[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_600 (BatchN (None, 7, 7, 128)    384         conv2d_600[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_595 (Activation)     (None, 7, 7, 128)    0           batch_normalization_595[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_600 (Activation)     (None, 7, 7, 128)    0           batch_normalization_600[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_596 (Conv2D)             (None, 7, 7, 128)    114688      activation_595[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_601 (Conv2D)             (None, 7, 7, 128)    114688      activation_600[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_596 (BatchN (None, 7, 7, 128)    384         conv2d_596[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_601 (BatchN (None, 7, 7, 128)    384         conv2d_601[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_596 (Activation)     (None, 7, 7, 128)    0           batch_normalization_596[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_601 (Activation)     (None, 7, 7, 128)    0           batch_normalization_601[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_57 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_594 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_597 (Conv2D)             (None, 7, 7, 192)    172032      activation_596[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_602 (Conv2D)             (None, 7, 7, 192)    172032      activation_601[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_603 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_57[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_594 (BatchN (None, 7, 7, 192)    576         conv2d_594[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_597 (BatchN (None, 7, 7, 192)    576         conv2d_597[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_602 (BatchN (None, 7, 7, 192)    576         conv2d_602[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_603 (BatchN (None, 7, 7, 192)    576         conv2d_603[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_594 (Activation)     (None, 7, 7, 192)    0           batch_normalization_594[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_597 (Activation)     (None, 7, 7, 192)    0           batch_normalization_597[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_602 (Activation)     (None, 7, 7, 192)    0           batch_normalization_602[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_603 (Activation)     (None, 7, 7, 192)    0           batch_normalization_603[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_594[0][0]             \n",
      "                                                                 activation_597[0][0]             \n",
      "                                                                 activation_602[0][0]             \n",
      "                                                                 activation_603[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_608 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_608 (BatchN (None, 7, 7, 160)    480         conv2d_608[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_608 (Activation)     (None, 7, 7, 160)    0           batch_normalization_608[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_609 (Conv2D)             (None, 7, 7, 160)    179200      activation_608[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_609 (BatchN (None, 7, 7, 160)    480         conv2d_609[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_609 (Activation)     (None, 7, 7, 160)    0           batch_normalization_609[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_605 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_610 (Conv2D)             (None, 7, 7, 160)    179200      activation_609[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_605 (BatchN (None, 7, 7, 160)    480         conv2d_605[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_610 (BatchN (None, 7, 7, 160)    480         conv2d_610[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_605 (Activation)     (None, 7, 7, 160)    0           batch_normalization_605[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_610 (Activation)     (None, 7, 7, 160)    0           batch_normalization_610[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_606 (Conv2D)             (None, 7, 7, 160)    179200      activation_605[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_611 (Conv2D)             (None, 7, 7, 160)    179200      activation_610[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_606 (BatchN (None, 7, 7, 160)    480         conv2d_606[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_611 (BatchN (None, 7, 7, 160)    480         conv2d_611[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_606 (Activation)     (None, 7, 7, 160)    0           batch_normalization_606[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_611 (Activation)     (None, 7, 7, 160)    0           batch_normalization_611[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_58 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_604 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_607 (Conv2D)             (None, 7, 7, 192)    215040      activation_606[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_612 (Conv2D)             (None, 7, 7, 192)    215040      activation_611[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_613 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_58[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_604 (BatchN (None, 7, 7, 192)    576         conv2d_604[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_607 (BatchN (None, 7, 7, 192)    576         conv2d_607[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_612 (BatchN (None, 7, 7, 192)    576         conv2d_612[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_613 (BatchN (None, 7, 7, 192)    576         conv2d_613[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_604 (Activation)     (None, 7, 7, 192)    0           batch_normalization_604[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_607 (Activation)     (None, 7, 7, 192)    0           batch_normalization_607[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_612 (Activation)     (None, 7, 7, 192)    0           batch_normalization_612[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_613 (Activation)     (None, 7, 7, 192)    0           batch_normalization_613[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_604[0][0]             \n",
      "                                                                 activation_607[0][0]             \n",
      "                                                                 activation_612[0][0]             \n",
      "                                                                 activation_613[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_618 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_618 (BatchN (None, 7, 7, 160)    480         conv2d_618[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_618 (Activation)     (None, 7, 7, 160)    0           batch_normalization_618[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_619 (Conv2D)             (None, 7, 7, 160)    179200      activation_618[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_619 (BatchN (None, 7, 7, 160)    480         conv2d_619[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_619 (Activation)     (None, 7, 7, 160)    0           batch_normalization_619[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_615 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_620 (Conv2D)             (None, 7, 7, 160)    179200      activation_619[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_615 (BatchN (None, 7, 7, 160)    480         conv2d_615[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_620 (BatchN (None, 7, 7, 160)    480         conv2d_620[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_615 (Activation)     (None, 7, 7, 160)    0           batch_normalization_615[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_620 (Activation)     (None, 7, 7, 160)    0           batch_normalization_620[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_616 (Conv2D)             (None, 7, 7, 160)    179200      activation_615[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_621 (Conv2D)             (None, 7, 7, 160)    179200      activation_620[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_616 (BatchN (None, 7, 7, 160)    480         conv2d_616[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_621 (BatchN (None, 7, 7, 160)    480         conv2d_621[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_616 (Activation)     (None, 7, 7, 160)    0           batch_normalization_616[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_621 (Activation)     (None, 7, 7, 160)    0           batch_normalization_621[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_59 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_614 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_617 (Conv2D)             (None, 7, 7, 192)    215040      activation_616[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_622 (Conv2D)             (None, 7, 7, 192)    215040      activation_621[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_623 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_59[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_614 (BatchN (None, 7, 7, 192)    576         conv2d_614[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_617 (BatchN (None, 7, 7, 192)    576         conv2d_617[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_622 (BatchN (None, 7, 7, 192)    576         conv2d_622[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_623 (BatchN (None, 7, 7, 192)    576         conv2d_623[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_614 (Activation)     (None, 7, 7, 192)    0           batch_normalization_614[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_617 (Activation)     (None, 7, 7, 192)    0           batch_normalization_617[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_622 (Activation)     (None, 7, 7, 192)    0           batch_normalization_622[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_623 (Activation)     (None, 7, 7, 192)    0           batch_normalization_623[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_614[0][0]             \n",
      "                                                                 activation_617[0][0]             \n",
      "                                                                 activation_622[0][0]             \n",
      "                                                                 activation_623[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_628 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_628 (BatchN (None, 7, 7, 192)    576         conv2d_628[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_628 (Activation)     (None, 7, 7, 192)    0           batch_normalization_628[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_629 (Conv2D)             (None, 7, 7, 192)    258048      activation_628[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_629 (BatchN (None, 7, 7, 192)    576         conv2d_629[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_629 (Activation)     (None, 7, 7, 192)    0           batch_normalization_629[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_625 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_630 (Conv2D)             (None, 7, 7, 192)    258048      activation_629[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_625 (BatchN (None, 7, 7, 192)    576         conv2d_625[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_630 (BatchN (None, 7, 7, 192)    576         conv2d_630[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_625 (Activation)     (None, 7, 7, 192)    0           batch_normalization_625[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_630 (Activation)     (None, 7, 7, 192)    0           batch_normalization_630[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_626 (Conv2D)             (None, 7, 7, 192)    258048      activation_625[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_631 (Conv2D)             (None, 7, 7, 192)    258048      activation_630[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_626 (BatchN (None, 7, 7, 192)    576         conv2d_626[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_631 (BatchN (None, 7, 7, 192)    576         conv2d_631[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_626 (Activation)     (None, 7, 7, 192)    0           batch_normalization_626[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_631 (Activation)     (None, 7, 7, 192)    0           batch_normalization_631[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_60 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_624 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_627 (Conv2D)             (None, 7, 7, 192)    258048      activation_626[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_632 (Conv2D)             (None, 7, 7, 192)    258048      activation_631[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_633 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_60[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_624 (BatchN (None, 7, 7, 192)    576         conv2d_624[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_627 (BatchN (None, 7, 7, 192)    576         conv2d_627[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_632 (BatchN (None, 7, 7, 192)    576         conv2d_632[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_633 (BatchN (None, 7, 7, 192)    576         conv2d_633[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_624 (Activation)     (None, 7, 7, 192)    0           batch_normalization_624[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_627 (Activation)     (None, 7, 7, 192)    0           batch_normalization_627[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_632 (Activation)     (None, 7, 7, 192)    0           batch_normalization_632[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_633 (Activation)     (None, 7, 7, 192)    0           batch_normalization_633[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_624[0][0]             \n",
      "                                                                 activation_627[0][0]             \n",
      "                                                                 activation_632[0][0]             \n",
      "                                                                 activation_633[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1024)         38536192    flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1024)         0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 1)            1025        dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 47,512,481\n",
      "Trainable params: 38,537,217\n",
      "Non-trainable params: 8,975,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation='relu'# Your Code Here\n",
    "                )(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2\n",
    "                   # Your Code Here\n",
    "                  )(x)                  \n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense  (1, activation='sigmoid'\n",
    "                   # Your Code Here\n",
    "                  )(x)           \n",
    "\n",
    "model = Model(  pre_trained_model.input\n",
    "              # Your Code Here\n",
    "              , x) \n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = 'binary_crossentropy'# Your Code Here\n",
    "              , metrics =  ['acc']# Your Code Here\n",
    "             )\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Expected output will be large. Last few lines should be:\n",
    "\n",
    "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
    "#                                                                  activation_251[0][0]             \n",
    "#                                                                  activation_256[0][0]             \n",
    "#                                                                  activation_257[0][0]             \n",
    "# __________________________________________________________________________________________________\n",
    "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
    "# __________________________________________________________________________________________________\n",
    "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
    "# ==================================================================================================\n",
    "# Total params: 47,512,481\n",
    "# Trainable params: 38,537,217\n",
    "# Non-trainable params: 8,975,264\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HrnL_IQ8knWA"
   },
   "outputs": [],
   "source": [
    "# Get the Horse or Human dataset\n",
    "path_horse_or_human = f\"{getcwd()}/../tmp2/horse-or-human.zip\"\n",
    "# Get the Horse or Human Validation dataset\n",
    "path_validation_horse_or_human = f\"{getcwd()}/../tmp2/validation-horse-or-human.zip\"\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree('/tmp')\n",
    "local_zip = path_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/training')\n",
    "zip_ref.close()\n",
    "\n",
    "local_zip = path_validation_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/validation')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9okX7_ovskI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "527\n",
      "128\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "# Define our example directories and files\n",
    "train_dir = '/tmp/training'\n",
    "validation_dir = '/tmp/validation'\n",
    "\n",
    "train_horses_dir = os.path.join(train_dir, 'horses')# Your Code Here\n",
    "train_humans_dir = os.path.join(train_dir, 'humans')# Your Code Here\n",
    "validation_horses_dir = os.path.join(validation_dir, 'horses')# Your Code Here\n",
    "validation_humans_dir = os.path.join(validation_dir, 'humans')# Your Code Here\n",
    "\n",
    "train_horses_fnames = os.listdir(train_horses_dir)# Your Code Here\n",
    "train_humans_fnames = os.listdir(train_humans_dir)# Your Code Here\n",
    "validation_horses_fnames = os.listdir(validation_horses_dir)# Your Code Here\n",
    "validation_humans_fnames = os.listdir(validation_humans_dir)# Your Code Here\n",
    "\n",
    "print(len(train_horses_fnames)# Your Code Here \n",
    "     )\n",
    "print(len(train_humans_fnames)# Your Code Here\n",
    ")\n",
    "print(len(validation_horses_fnames)# Your Code Here\n",
    ")\n",
    "print(len(validation_humans_fnames)# Your Code Here\n",
    ")\n",
    "\n",
    "# Expected Output:\n",
    "# 500\n",
    "# 527\n",
    "# 128\n",
    "# 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4s8HckqGlnb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
    "                                    rotation_range = 40,\n",
    "                                    width_shift_range = 0.2,\n",
    "                                    height_shift_range = 0.2,\n",
    "                                    shear_range = 0.2,\n",
    "                                    zoom_range = 0.2,\n",
    "                                    horizontal_flip = True\n",
    "                                    # Your Code Here\n",
    "                                    )\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0/255. # Your Code Here\n",
    "                                 )\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = 'binary', \n",
    "                                                    target_size = (150, 150)\n",
    "                                                    # Your Code Here\n",
    "                                                   )     \n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
    "                                                          batch_size  = 20,\n",
    "                                                          class_mode  = 'binary', \n",
    "                                                          target_size = (150, 150)# Your Code Here\n",
    "                                                        )\n",
    "\n",
    "# Expected Output:\n",
    "# Found 1027 images belonging to 2 classes.\n",
    "# Found 256 images belonging to 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Blhq2MAUeyGA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "52/52 [==============================] - 58s 1s/step - loss: 0.2813 - acc: 0.8685 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 2/3\n",
      "52/52 [==============================] - 60s 1s/step - loss: 0.0944 - acc: 0.9698 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 3/3\n",
      "51/52 [============================>.] - ETA: 0s - loss: 0.0895 - acc: 0.9722\n",
      "Reached 97.0% accuracy so cancelling training!\n",
      "52/52 [==============================] - 57s 1s/step - loss: 0.0904 - acc: 0.9718 - val_loss: 1.5219e-04 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Run this and see how many epochs it should take before the callback\n",
    "# fires, and stops training at 97% accuracy\n",
    "\n",
    "callbacks = myCallback()# Your Code Here\n",
    "history = model.fit_generator(train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            #steps_per_epoch = 100,\n",
    "            epochs = 3,\n",
    "            #validation_steps = 50,\n",
    "            callbacks = [callbacks],\n",
    "            verbose = 1\n",
    "            # Your Code Here (set epochs = 3)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C2Fp6Se9rKuL"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now click the 'Submit Assignment' button above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When you're done or would like to take a break, please run the two cells below to save your work and close the Notebook. This will free up resources for your fellow learners. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise 7 - Question.ipynb",
   "provenance": []
  },
  "coursera": {
   "course_slug": "convolutional-neural-networks-tensorflow",
   "graded_item_id": "csg1x",
   "launcher_item_id": "GpKYz"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
